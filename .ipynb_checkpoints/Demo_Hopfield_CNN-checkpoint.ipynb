{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ce00a5-cd41-46ba-a1bb-835d3cc8ec81",
   "metadata": {},
   "source": [
    "# HDNN-ArtifactBrainState\n",
    "HDNN-ArtifactBrainState is a cutting-edge project that integrates Hopfield networks with deep neural networks to enhance brain state decoding, focusing on resilience against artifacts. This notebook, and associated utilities, house the code and resources for implementing the HDNN framework described in our recent publication.\n",
    "\n",
    "<img src=\"data/HDNN-pipeline.png\" width=\"1000px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3c601-1a6e-46cb-b8c6-fba1542b5504",
   "metadata": {},
   "source": [
    "## Importing the code and defining the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3ee8f-d09f-42b9-a298-1462987bb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as fx\n",
    "from numpy import mean\n",
    "import pickle\n",
    "\n",
    "subj = 'subject1' # name of our dataset (only subject1 for this test-case)\n",
    "num_samples_per_state = 100 # demo dataset has up to 288 samples per each state\n",
    "segment_length = 250 # 250 millisecond windows for our demo dataset\n",
    "n_epochs = 10 \n",
    "\n",
    "imgs = [10,20] # size of the images\n",
    "err_percentages = [0.05, 0.1] # percentage of total pixel corruption to be added in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad8f8d-4edb-4f22-9f47-dabed20268b9",
   "metadata": {},
   "source": [
    "## Case 1: No Artifacts are added to the data.\n",
    "The following code will run through different imgs sizes and err_percentages. As it is the \"No Artifacts\" case, the data won't include any type of artifacts.\n",
    "\n",
    "A file `res_noartifact.pkl` will be created to save the accuracies and confusion matrices for each case. You can access that results by loading the file or accessing the variable `res_noartifact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5b4c3-0caa-4ade-b4a7-f2b191614f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load res_noartifact from disk if it exists\n",
    "try:\n",
    "    with open('res_noartifact.pkl', 'rb') as f:\n",
    "        res_noartifact = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    res_noartifact = {}  # Initialize an empty dictionary if file not found\n",
    "\n",
    "for err in err_percentages:\n",
    "    for img_size in imgs:\n",
    "        if (err, img_size) in res_noartifact:\n",
    "            print('skipped!', err, img_size)\n",
    "            continue\n",
    "\n",
    "        temp_test_acc = []\n",
    "        temp_cm_normalized = []\n",
    "        \n",
    "        n = 2 # Change this to n runs\n",
    "        for _ in range(n):  \n",
    "            test_acc, cm_normalized = fx.pipeline_noartifact(subj, num_samples_per_state, img_size, segment_length, err, n_epochs)\n",
    "            temp_test_acc.append(test_acc)\n",
    "            temp_cm_normalized.append(cm_normalized)\n",
    "\n",
    "        # average values after n runs\n",
    "        avg_test_acc = mean(temp_test_acc)\n",
    "        avg_cm_normalized = mean(temp_cm_normalized, axis=0)\n",
    "\n",
    "        # Save the averaged results in the dictionary\n",
    "        res_noartifact[(err, img_size)] = {'test_acc': avg_test_acc, 'cm_normalized': avg_cm_normalized}\n",
    "\n",
    "        # Save to disk after every iteration\n",
    "        with open('res_noartifact.pkl', 'wb') as f:\n",
    "            pickle.dump(res_noartifact, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ba137-0f87-4117-a8fd-e17346a482bd",
   "metadata": {},
   "source": [
    "## Case 2: Hopfield + CNN model\n",
    "The following code will run through different imgs sizes and err_percentages. Artifacts are added to the data depending on the `err_percentages` chosen and treated via the Hopfield model.\n",
    "\n",
    "A file `results_hop.pkl` will be created to save the accuracies and confusion matrices for each case. You can access that results by loading the file or accessing the variable `results_2hop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a9aa9-1997-4f41-b4af-ba744401ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('results_hop.pkl', 'rb') as f:\n",
    "        results_2hop = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    results_2hop = {}  # Initialize an empty dictionary if file not found\n",
    "\n",
    "for err in err_percentages:\n",
    "    for img_size in imgs:\n",
    "        \n",
    "        # Skip computation if this combination already exists\n",
    "        if (err, img_size) in results_2hop:\n",
    "            print('skipped!', err, img_size)\n",
    "            continue\n",
    "\n",
    "        temp_test_acc = []\n",
    "        temp_cm_normalized = []\n",
    "\n",
    "        for _ in range(2):  # Change this to 5 if you meant 5 runs\n",
    "            test_acc, cm_normalized = fx.pipeline_hopfield_rec(subj, num_samples_per_state, img_size, segment_length, err, n_epochs)\n",
    "            temp_test_acc.append(test_acc)\n",
    "            temp_cm_normalized.append(cm_normalized)\n",
    "\n",
    "        avg_test_acc = mean(temp_test_acc)\n",
    "        avg_cm_normalized = mean(temp_cm_normalized, axis=0)\n",
    "\n",
    "        # Save the averaged results in the dictionary\n",
    "        results_2hop[(err, img_size)] = {'test_acc': avg_test_acc, 'cm_normalized': avg_cm_normalized}\n",
    "\n",
    "        # Save to disk after every iteration\n",
    "        with open('results_hop.pkl', 'wb') as f:\n",
    "            pickle.dump(results_2hop, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b26cb5-3045-4090-9824-93e924063363",
   "metadata": {},
   "source": [
    "## Case 3: Baseline\n",
    "The following code will run through different imgs sizes and err_percentages. Artifacts are added to the data depending on the `err_percentages` chosen. Artifacts are not treated by the Hopfield model. \n",
    "\n",
    "A file `results.pkl` will be created to save the accuracies and confusion matrices for each case. You can access that results by loading the file or accessing the variable `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52ef8e-be16-4d11-8467-9d866e0154f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load results from disk if it exists\n",
    "try:\n",
    "    with open('results.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    results = {}  # Initialize an empty dictionary if file not found\n",
    "\n",
    "for err in err_percentages:\n",
    "    for img_size in imgs:\n",
    "\n",
    "        # Skip computation if this combination already exists\n",
    "        if (err, img_size) in results:\n",
    "            print('skipped!', err, img_size)\n",
    "            continue\n",
    "\n",
    "        temp_test_acc = []  \n",
    "        temp_cm_normalized = [] \n",
    "\n",
    "        n = 2 # number of runs\n",
    "        for _ in range(n): \n",
    "            test_acc, cm_normalized = fx.pipeline(subj, num_samples_per_state, img_size, segment_length, err, n_epochs)\n",
    "            temp_test_acc.append(test_acc)\n",
    "            temp_cm_normalized.append(cm_normalized)\n",
    "\n",
    "        avg_test_acc = mean(temp_test_acc)\n",
    "        avg_cm_normalized = mean(temp_cm_normalized, axis=0)\n",
    "\n",
    "        results[(err, img_size)] = {'test_acc': avg_test_acc, 'cm_normalized': avg_cm_normalized}\n",
    "\n",
    "        with open('results.pkl', 'wb') as f:\n",
    "            pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbffc85-6945-453b-a597-d0097d6fb285",
   "metadata": {},
   "source": [
    "## Plotting \n",
    "- Load the results of the three models\n",
    "- Compare the accuracies of the three models for the different `err_percentages` and `img_size` chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c4222-e21b-4a99-8263-b6486518f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "with open('res_noartifact.pkl', 'rb') as f:\n",
    "    res_noartifact = pickle.load(f)\n",
    "\n",
    "with open('results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "with open('results_hop.pkl', 'rb') as f:\n",
    "    results_2hop_v2 = pickle.load(f)\n",
    "\n",
    "imgs = [10, 20]\n",
    "err_percentages = err_percentages\n",
    "\n",
    "default_value = {'test_acc': -0, 'cm_normalized': np.array([[-0, -0, -1], [-1, -1, -1], [-1, -1, -1]]), 'cm_m': -0}\n",
    "\n",
    "datasets = [results, results_2hop_v2, res_noartifact]\n",
    "\n",
    "# Loop through each dataset to populate missing (err, img) combinations\n",
    "for dataset in datasets:\n",
    "    for img in imgs:\n",
    "        for err in err_percentages:\n",
    "            if (err, img) not in dataset:\n",
    "                dataset[(err, img)] = default_value  # Using default_value with 'cm_m'\n",
    "            cm_normalized = dataset[(err, img)]['cm_normalized']\n",
    "            cm_m = np.mean(np.diag(cm_normalized))\n",
    "            dataset[(err, img)]['cm_m'] = cm_m  # Storing the mean of the diagonal\n",
    "\n",
    "# Setting plot aesthetics\n",
    "font = {'family': 'Arial', 'weight': 'normal', 'size': 18}\n",
    "plt.rc('font', **font)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "datasets = [results,results_2hop_v2,res_noartifact]\n",
    "colors = ['g', 'b', 'r']\n",
    "titles = ['Baseline', 'Hopfield-rec', 'No-artifacts']\n",
    "\n",
    "datasets = [results,results_2hop_v2,res_noartifact]\n",
    "colors = ['g', 'b', 'r']\n",
    "dataset_names = ['Baseline', 'Hopfield-rec', 'No-artifacts']\n",
    "\n",
    "for idx, (data, color, title) in enumerate(zip(datasets, colors, titles)):\n",
    "\n",
    "    ax = axes[idx]\n",
    "    for img_size in [10, 20]:\n",
    "        acc_values = [data[(err, img_size)]['cm_m'] for err in err_percentages if (err, img_size) in data]\n",
    "\n",
    "        ax.plot(err_percentages, acc_values, marker='o', label=f\"Image Size {img_size}\")\n",
    "    \n",
    "    ax.set_xticks(err_percentages)\n",
    "    ax.set_yticks([0.25, 0.50, 0.75, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title(f\"{title} - Diagonal CM vs. Error\")\n",
    "    ax.set_xlabel('Error Percentage')\n",
    "    ax.set_ylabel('Test Mean of diagonal CM  (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "for idx, (data, color, title) in enumerate(zip(datasets, colors, titles)):\n",
    "    ax = axes[idx]\n",
    "    for err in err_percentages:\n",
    "        acc_values = [data[(err, img_size)]['cm_m'] for img_size in imgs]\n",
    "        ax.plot(imgs, acc_values, marker='o', label=f\"Error {err}\")\n",
    "\n",
    "    ax.set_xticks(imgs)\n",
    "    ax.set_yticks([0.25, 0.50, 0.75, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title(f\"{title} - Diagonal CM vs. Image Size\")\n",
    "    ax.set_xlabel('Image Size')\n",
    "    ax.set_ylabel('Test Mean of diagonal CM  (%)')\n",
    "    ax.grid(True, linestyle='--')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "merged_results = {}\n",
    "\n",
    "datasets = [results_2hop, res_noartifact, results]\n",
    "dataset_names = ['Hopfield-rec', 'No-artifacts', 'Baseline']\n",
    "font = {'family': 'Times New Roman', 'weight': 'normal', 'size': 18}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 4))\n",
    "\n",
    "datasets = [results,results_2hop_v2,res_noartifact]\n",
    "colors = ['g', 'b', 'r']\n",
    "titles = ['Baseline', 'Hopfield-rec', 'No-artifacts']\n",
    "datasets = [results,results_2hop_v2,res_noartifact]\n",
    "colors = ['g', 'b', 'r']\n",
    "dataset_names = ['Baseline', 'Hopfield-rec', 'No-artifacts']\n",
    "\n",
    "\n",
    "for idx, (data, color, title) in enumerate(zip(datasets, colors, titles)):\n",
    "    for img_size in [10]:\n",
    "        acc_values = [data[(err, img_size)]['cm_m'] for err in err_percentages if (err, img_size) in data]\n",
    "        ax[0].plot(err_percentages, acc_values, marker='o', label=title, color=color)\n",
    "\n",
    "for idx, (data, color, title) in enumerate(zip(datasets, colors, titles)):\n",
    "    for img_size in [20]:\n",
    "        acc_values = [data[(err, img_size)]['cm_m'] for err in err_percentages if (err, img_size) in data]\n",
    "        ax[1].plot(err_percentages, acc_values, marker='o', label=title, color=color)\n",
    "\n",
    "ax[0].set_xticks(err_percentages)\n",
    "ax[0].set_yticks([0.4, 0.75, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_title(f'Mean of diagonal CM  vs. Error img_size={10}')\n",
    "ax[0].set_xlabel('Error Percentage')\n",
    "ax[0].set_ylabel('Test Mean of diagonal CM  (%)')\n",
    "ax[0].grid(True, linestyle='--')\n",
    "ax[0].legend()\n",
    "ax[1].set_xticks(err_percentages)\n",
    "ax[1].set_yticks([0.4, 0.75, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_title(f'Mean of diagonal CM  vs. Error img_size={20}')\n",
    "ax[1].set_xlabel('Error Percentage')\n",
    "ax[1].set_ylabel('Test Mean of diagonal CM  (%)')\n",
    "ax[1].grid(True, linestyle='--')\n",
    "ax[1].legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
